# -*- coding: utf-8 -*-
"""name_entity_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l_Ysc9etfgzxVdCwOlJA2dJ-9z45xpYS
"""

from google.colab import drive
drive.mount('/content/drive')

import spacy

spacy_nlp = spacy.load('en')
nlp = spacy.load("en_core_web_sm")

from spacy import displacy
from collections import Counter
import en_core_web_sm
nlp2 = en_core_web_sm.load()

import nltk

print('NLTK version: %s' % (nltk.__version__))
from nltk  import word_tokenize,pos_tag,ne_chunk
nltk.download('words')
nltk.download('averaged_perceptron_tagger')
nltk.download('punkt')
nltk.download('maxent_ne_chunker')

#using spacy
sentence = 'My name is Francis Obasi, I am data analyst, I live in lagos state, Nigeria and i work with Nigerian Breweries Plc'
sentence2 = input('Enter sentence here: ')
document = nlp2(sentence2)

#Combining both functions below
data_dic = dict()

def get_items2():
  def article_precess(document):
    for element in document.ents:
      data_dic[element.label_] = element
  article_precess(document)
  print(' location ' ' = ' + str(data_dic.get('GPE')))
  print(' Organization ' ' = ' + str(data_dic.get('ORG')))
  print(' Name '' = '+ str(data_dic.get('PERSON')))
get_items2()

#data_dic = dict()
#def article_precess(document):
 # for element in document.ents:
   # data_dic[element.label_] = element
  #  
#article_precess(document)

#def get_items2():
 # print(' location ' ' = ' + str(data_dic.get('GPE')))
  #print(' Organization ' ' = ' + str(data_dic.get('ORG')))
  #print('Name '' = '+ str(data_dic.get('PERSON')))
#get_items2()

